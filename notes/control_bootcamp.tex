\documentclass{article}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{bookmark}

\hypersetup{
  colorlinks=true,
  linkcolor=blue,
  urlcolor=blue
}

\renewcommand{\vec}[1]{\boldsymbol{\mathbf{#1}}}
\newcommand{\dvec}[1]{\dot{\vec{#1}}}

\begin{document}

This document contains my notes on \href{https://www.youtube.com/playlist?list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m}{Steve Brunton's Control Bootcamp video series}. Each section corresponds to the video of the same title.

\tableofcontents

\section{Overview}

\begin{itemize}
  \item \textbf{Passive controls} attempt to control a system passively, i.e. they are built into the system and don't vary based on observations of the system.

  \item \textbf{Active controls} attempt to control a system actively, i.e. they change their behaviour based on observations of the system.

  \item \textbf{Open-loop controllers} don't observe the output of the system — their inputs are predetermined. One downside of this approach is that you may unnecessarily input energy into the system when it already has the desired output.

  \item \textbf{Closed-loop controllers} observe the output of the system to determine their inputs. They have several benefits over open-loop controllers:

        \begin{itemize}
          \item They handle uncertainty in the system, e.g. if you don't always know how the system will respond, or if your model isn't completely accurate.

          \item They handle disturbances in the system, e.g. if someone pushes a self-balancing inverted pendulum. It may not be possible to account for these in the model.

          \item They can be more energy efficient than open-loop controllers, i.e. they don't have the downside mentioned above.
        \end{itemize}

  \item The mathematical model used in this course is a state-space based system of linear differential equations \[\dvec{x} = \vec{A} \vec{x}\] where $\vec{x}$ is the \textbf{state vector} — a vector containing all the system's values of interest — and $\dvec{x}$ are their rates of change at a time $t$.

  \item The solution to the above equation is \[\vec{x}(t) = e^{\vec{A} t} \vec{x}(0)\] and the eigenvalues of $\vec{A}$ can be used to determine the stability of the system, e.g. if they all have negative real components the system is stable.

  \item Control is introduced to the system by modifying the equation to \[\dvec{x} = \vec{A} \vec{x} + \vec{B} \vec{u}\] where $\vec{B}$ is a coefficient matrix and $\vec{u}$ is the input to the system.

  \item If we make the input to the system \[\vec{u} = -\vec{K} \vec{x}\] then \begin{align*}
          \dvec{x} & = \vec{A} \vec{x} - \vec{B} \vec{K} \vec{x} \\
                   & = (\vec{A} - \vec{B} \vec{K}) \vec{x}
        \end{align*} and now it is the eigenvalues of $\vec{A} - \vec{B} \vec{K}$ that determine the stability of the system, i.e. we can make an unstable system stable by appropriate choice of inputs.
\end{itemize}

\section{Linear Systems}

\begin{itemize}
  \item The solution to the linear system of differential equations \[\dvec{x} = \vec{A} \vec{x}\] is \[\vec{x}(t) = e^{\vec{A} t} \vec{x}_0\] where \begin{align*}
          e^{\vec{A} t} & = \sum_{k = 0}^\infty \frac{(\vec{A} t)^k}{k!}                                       \\
                        & = \vec{I} + \vec{A} t + \frac{\vec{A}^2 t^2}{2!} + \frac{\vec{A}^3 t^3}{3!} + \ldots
        \end{align*}

  \item If a matrix $\vec{A}$ has eigenvalues $\lambda_1, \ldots, \lambda_n$ and eigenvectors $\vec{k}_1, \ldots, \vec{k}_n$ then \[\vec{A} \vec{T} = \vec{T} \vec{D}\] or \[\vec{T}^{-1} \vec{A} \vec{T} = \vec{D}\] where \[\vec{T} = \begin{pmatrix}
            \vec{k}_1 & \cdots & \vec{k}_n
          \end{pmatrix}\] and \[\vec{D} = \begin{pmatrix}
            \lambda_1 &        & 0         \\
                      & \ddots &           \\
            0         &        & \lambda_n
          \end{pmatrix}.\]

  \item Using the above gives \[e^{\vec{A} t} = \vec{T} e^{\vec{D} t} \vec{T}^{-1}\] which is simpler because $e^{\vec{D} t}$ is easy to calculate.

  \item If we define $\vec{z}$ to be $\vec{x}$ transformed to the eigenvector basis, i.e. \[\vec{x} = \vec{T} \vec{z}\] and \[\dvec{x} = \vec{T} \dvec{z}\] then \begin{align*}
          \vec{z}  & = \vec{T}^{-1} \vec{x}                 \\
          \dvec{z} & = \vec{T}^{-1} \dvec{x}                \\
                   & = \vec{T}^{-1} \vec{A} \vec{x}         \\
                   & = \vec{T}^{-1} \vec{A} \vec{T} \vec{z} \\
                   & = \vec{D} \vec{z}
        \end{align*} where $\vec{D}$ is the diagonal matrix consisting of the eigenvalues of $\vec{A}$. The solution to this equation is \[\vec{z}(t) = e^{\vec{D} t} \vec{z}_0\] where \[e^{\vec{D} t} = \begin{pmatrix}
            e^{\lambda_1 t} &        & 0               \\
                            & \ddots &                 \\
            0               &        & e^{\lambda_n t}
          \end{pmatrix},\] i.e. the equations are uncoupled such that \begin{align*}
          z_1(t) & = z_{0,1} e^{\lambda_1 t}  \\
          \vdots                              \\
          z_n(t) & = z_{0,n} e^{\lambda_n t}.
        \end{align*}

  \item The equivalence between the original and eigenvector coordinates can be seen by manipulating the solution \begin{align*}
          \vec{x}(t) & = e^{\vec{A} t} \vec{x}_0                      \\
                     & = \vec{T} e^{\vec{D} t} \vec{T}^{-1} \vec{x}_0 \\
                     & = \vec{T} e^{\vec{D} t} \vec{z}_0              \\
                     & = \vec{T} \vec{z}(t).
        \end{align*}
\end{itemize}

\section{Stability and Eigenvalues}

\begin{itemize}
  \item A system $\dvec{x} = \vec{A} \vec{x}$ is stable if and only if all of the eigenvalues of $\vec{A}$ have negative real parts. This is because the solution is of the form\footnote{See \href{https://www.youtube.com/watch?v=nyqJJdhReiA\#t=15m15s}{here} for a proof of why $e^{\vec{A} t} = \vec{T} e^{\vec{D} t} \vec{T}^{-1}$.} \[\vec{x} = \vec{T} e^{\vec{D} t} \vec{T}^{-1} \vec{x}_0\] where \[e^{\vec{D} t} = \begin{pmatrix}
            e^{\lambda_1 t} &        & 0               \\
                            & \ddots &                 \\
            0               &        & e^{\lambda_n t}
          \end{pmatrix}\] and \[e^{\lambda_1 t} = e^{(a + i b) t} = e^{a t} e^{i b t}\] which is only stable if $a < 0$.

  \item Sometimes you can make a system stable (i.e. make all the eigenvalues have negative real parts) via the control term $\vec{B} \vec{u}$.

  \item In a real-world system, control signals will be sent and observations received in discrete steps rather than continuously. A variation of the equation that captures this is \[\vec{x}_{k + 1} = \tilde{\vec{A}} \vec{x}_k\] where \[\tilde{\vec{A}} = e^{\vec{A} \Delta t}.\] In other words, \begin{align*}
          \vec{x}_k & = \tilde{\vec{A}}^k \vec{x}_0                                        \\
                    & = (\tilde{\vec{T}} \tilde{\vec{D}} \tilde{\vec{T}}^{-1})^k \vec{x_0} \\
                    & = \tilde{\vec{T}} \tilde{\vec{D}}^k \tilde{\vec{T}}^{-1} \vec{x}_0
        \end{align*} where \[\tilde{\vec{D}}^k = \begin{pmatrix}
            \tilde{\lambda}_1^k &        & 0                   \\
                                & \ddots &                     \\
            0                   &        & \tilde{\lambda}_n^k
          \end{pmatrix}\] so the discrete system is stable if the moduli of all the eigenvalues of $\tilde{\vec{A}}$ are less than or equal to $1$.

  \item Note that the stability criteria of a discrete system (the moduli of of all eigenvalues must be less than $1$) differs from that of a continuous system (the real parts of all eigenvalues must be negative) because we're raising $\tilde{\vec{A}} = e^{\vec{A} \Delta t}$ to a power directly rather than exponentiating it so both the real and imaginary components of its eigenvalues contribute to the ``radius'' \begin{align*}
          \lambda_n^k & = (a + i b)^k                                     \\
                      & = (\sqrt{a^2 + b^2} e^{i \arctan \frac{b}{a}})^k  \\
                      & = \sqrt{a^2 + b^2}^k e^{i k \arctan \frac{b}{a}}.
        \end{align*}
\end{itemize}

\section{Linearizing Around a Fixed Point}

\begin{itemize}
  \item The \textbf{Jacobian matrix} of a vector-valued function of several variables $\vec{f} : \mathbb{R}^n \rightarrow \mathbb{R}^m$ is defined as \[D \vec{f} = \begin{pmatrix}
            \frac{\partial f_1}{\partial x_1} & \cdots & \frac{\partial f_1}{\partial x_n} \\
            \vdots                            & \ddots & \vdots                            \\
            \frac{\partial f_m}{\partial x_1} & \cdots & \frac{\partial f_m}{\partial x_n}
          \end{pmatrix}.\]

  \item If $\vec{x}$ is a point and $\Delta \vec{x}$ is a displacement, both in $\mathbb{R}^n$, the Jacobian matrix can be used to linearize $\vec{f}$ around $\vec{x}$ \[\vec{f}(\vec{x} + \Delta \vec{x}) \approx \vec{f}(\vec{x}) + D \vec{f}|_{\vec{x}} \Delta \vec{x}.\]

  \item To convert a nonlinear system $\dvec{x} = f(\vec{x})$ to a linear system $\dvec{x} = \vec{A} \vec{x}$:

        \begin{enumerate}
          \item Find fixed points $\overline{\vec{x}}$ such that $f(\overline{\vec{x}}) = \vec{0}$.

          \item Use the Jacobian matrix to linearize $f(\vec{x})$ about $\overline{\vec{x}}$, i.e. \[\dvec{x} = f(\vec{x})\] is approximated by \begin{align*}
                  \dvec{x} & = f(\overline{\vec{x}}) + D f|_{\overline{\vec{x}}} \Delta \vec{x} \\
                           & = D f|_{\overline{\vec{x}}} \Delta \vec{x}                         \\
                           & = \vec{A} \Delta \vec{x}
                \end{align*} where $\vec{A} = D f|_{\overline{\vec{x}}}$. However this is only valid if all eigenvalues of $\vec{A}$ have a nonzero real part.
        \end{enumerate}
\end{itemize}

\section{Controllability}

\begin{itemize}
  \item A system with control can be modelled using the equation \[\dvec{x} = \vec{A} \vec{x} + \vec{B} \vec{u}\] where $\vec{u}$ is the input to the system.

  \item If we can completely observe the state of the system, i.e. we have access to all state variables, we can let $\vec{u} = -\vec{K} \vec{x}$ and thus \begin{align*}
          \dvec{x} & = \vec{A} \vec{x} + \vec{B} \vec{u}         \\
                   & = \vec{A} \vec{x} - \vec{B} \vec{K} \vec{x} \\
                   & = (\vec{A} - \vec{B} \vec{K}) \vec{x}
        \end{align*} and we can control the eigenvalues/stability of the system via careful choice of $\vec{K}$.

  \item A system is said to be \textbf{controllable} if it's possible to choose $\vec{u} = -\vec{K} \vec{x}$ such that the system has any arbitrary eigenvalues and thus the state can be manipulated in any desired way.

  \item In most cases $\vec{A}$ (the linearized equations of motion) and $\vec{B}$ (the effects of various inputs) are predetermined and you only get to control $\vec{u}$.

  \item Some combinations of $\vec{A}$ and $\vec{B}$ are controllable and some aren't. For example, \begin{align*}
          \dvec{x}        & = \vec{A} \vec{x} + \vec{B} \vec{u}                 \\
          \begin{pmatrix}
            \dot{x}_1 \\
            \dot{x}_2
          \end{pmatrix} & = \begin{pmatrix}
                              1 & 0 \\
                              0 & 2
                            \end{pmatrix} \begin{pmatrix}
                                            x_1 \\
                                            x_2
                                          \end{pmatrix} + \begin{pmatrix}
                                                            0 \\
                                                            1
                                                          \end{pmatrix} \vec{u}
        \end{align*} isn't controllable because $\dot{x}_1 = x_1$ isn't affected by $\vec{u}$. However if $\vec{B}$ were instead \[\begin{pmatrix}
            1 & 0 \\
            0 & 1
          \end{pmatrix}\] the system would be controllable because $\vec{u}$ can affect both $\dot{x}_1$ and $\dot{x}_2$.

  \item A system with state space in $\mathbb{R}^n$ is controllable if the controllability matrix \[C = \begin{pmatrix}
            \vec{B} & \vec{A} \vec{B} & \vec{A}^2 \vec{B} & \cdots & \vec{A}^{n - 1} \vec{B}
          \end{pmatrix}\] has rank $n$.
\end{itemize}

\section{Controllability, Reachability, and Eigenvalue Placement}

\begin{itemize}
  \item The following are all equivalent:

        \begin{itemize}
          \item The system is controllable.

          \item It's possible to arbitrarily place the eigenvalues of the system by careful choice of $\vec{K}$.

          \item The state space is fully reachable, i.e. for any state in $\mathbb{R}^n$ there exist inputs $\vec{u}(t)$ that result in the system being in that state.
        \end{itemize}
\end{itemize}

\section{Controllability and the Discrete-Time Impulse Response}

\begin{itemize}
  \item The first column in the controllability matrix can be thought of as an initial ``kick'' to the system via the input vector $\vec{u}$ and each subsequent column can be thought of as the state of the system one time step later. This lets us see which dimensions of the state space can be controlled via input.
\end{itemize}

\section{Degrees of Controllability and Gramians}

\begin{itemize}
  \item The \textbf{Gramian} of a system is defined as \[W_t = \int_0^t e^{\vec{A} t} \vec{B} \vec{B}^T e^{\vec{A}^T \tau} \,d \tau.\] It is real-valued and symmetric so it has positive, real eigenvalues. If you sort the eigenvalues from largest to smallest, the same ordering of the associated eigenvectors is also ordering them from most to least controllable.

  \item The Gramian gives a finer grained answer to the question ``Is the system controllable?'' than the rank of the controllability matrix — it tells you how controllable it is in different dimsensions of the state space.

  \item A system is said to be \textbf{stabilisable} if all unstable eigenvectors of $\vec{A}$ are in the controllable subspace, i.e. it's OK if a subset of the state vector isn't controllable providing it's stable — it will stabilise by itself.
\end{itemize}

\end{document}