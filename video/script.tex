\documentclass{article}
\usepackage{amsmath} % For align*
\usepackage{circuitikz} % For circuit diagrams
\usepackage{bookmark} % For links
\usepackage{float} % For the [H] option on figures
\usepackage{graphicx} % For images
\usepackage{tikz} % For diagrams
\usepackage{siunitx} % For units

\graphicspath{{./images/}}
\hypersetup{
  colorlinks=true,
  linkcolor=blue,
  urlcolor=blue
}

\DeclareMathOperator{\rank}{rank}
\renewcommand{\vec}[1]{\boldsymbol{\mathbf{#1}}}
\newcommand{\dvec}[1]{\dot{\vec{#1}}}

\begin{document}

\tableofcontents

\section{Introduction}

I recently built this balancing pendulum on a cart. If you've ever tried to keep something like a broom or a stick upright on your hand you'll know it can be quite tricky! Gravity's constantly pulling it down, so if it’s not perfectly vertical it’ll start to fall. The same thing happens to the pendulum but the cart's programmed to move left and right in a way that keeps it upright.

In this video I’ll explain how I built it. I'll start by deriving the system's equations of motion, I'll apply some control theory to those equations to analyse the stability of the system and determine how to control it, I'll talk about how I physically built it, and finally I'll talk about the code that controls it.

The math will make the most sense if you're familiar with calculus and a little linear algebra, but if not, don't worry, you should still be able to follow along.

\section{Equations of Motion}

If we want to control this system we need to know how it behaves when the cart's free to move, so let’s derive its equations of motion. First we need to define our coordinate system and variables in a diagram:

\begin{figure}[h]
  \centering
  \begin{tikzpicture}
    % x
    \draw (-2, 0.3) -- (-2, 0.7);
    \draw[dashed] (-2, 0.5) -- node[above] {$x$} (0, 0.5);

    % Cart
    \draw (0, 0) rectangle node {$m_1$} (2, 1);

    % Pendulum
    \draw (1, 1) -- (0.5, 3);
    \draw[dashed] (1, 1) -- (1, 3);
    \draw (0.37, 3.4) node {$m_2$} circle (0.4cm);

    % l
    \node at (0.5, 1.8) {$l$};

    % Theta
    \draw (1, 2.8) arc (90:117:1);
    \node at (0.8, 2.5) {$\theta$};

    % Axes
\draw[->] (3, 0.5) -- (4, 0.5) node[right] {$x$};
\draw[->] (3, 0.5) -- (3, 1.5) node[above] {$y$};
  \end{tikzpicture}
\end{figure}

We have a cart of mass $m_1$ that can only move along the $x$-axis and its position $x$ is measured from some origin point. The cart is connected to a simple pendulum of length $l$ and mass $m_2$ which is at an angle $\theta$ from vertical.

With that out of the way, now we can determine the Lagrangian of the system which is defined as the difference between its kinetic and potential energies: $\mathcal{L} = T - U$. Well, what are those energies?

Starting with the cart, its kinetic energy is \[T_\text{cart} = \frac{1}{2} m_1 v^2\] but because it can only move along the $x$-axis its velocity has no $y$ component this is equivalent to \[T_\text{cart} = \frac{1}{2} m_1 \dot{x}^2\] I'm going to use Newton's notation for derivatives so when you see a dot or a double dot over a variable that's what that means. As for the cart's potential energy, it can't move up or down so its gravitational potential energy can't change and there's no springs or anything involved so we might as well set it to \[U_\text{cart} = 0.\]

Next, the pendulum. Because it's joined to the cart its $x$ coordinate changes as cart moves, and both of its coordinates change as it rotates. We can write its coordinates as \begin{align*}
  X & = x - l \sin \theta \\
  Y & = l \cos \theta.
\end{align*} Differentiating these equations with respect to time gives the $x$ and $y$ components of the pendulum's velocity \begin{align*}
  \dot{X} & = \dot{x} - l \dot{\theta} \cos \theta \\
  \dot{Y} & = -l \dot{\theta} \sin \theta.
\end{align*} Using the Pythagorean theorem we can combine these to find the squared magnitude of the pendulum's velocity \begin{align*}
  V^2 & = \dot{X}^2 + \dot{Y}^2                                                      \\
      & = (\dot{x} - l \dot{\theta} \cos \theta)^2 + (-l \dot{\theta} \sin \theta)^2 \\
      & = \dot{x}^2 - 2 l \dot{\theta} \dot{x} \cos \theta + l^2 \dot{\theta}^2
\end{align*}
and we can use this to find its kinetic energy \begin{align*}
T_\text{pendulum} & = \frac{1}{2} m_2 V^2                                                                          \\
                    & = \frac{1}{2} m_2 (\dot{x}^2 - 2 l \dot{\theta} \dot{x} \cos \theta + l^2 \dot{\theta}^2).
\end{align*} Unlike the cart, the pendulum's potential energy can change — as we saw, when it rotates it moves up and down so its gravitational potential energy changes. If we say its potential energy is $0$ when its $y$ coordinate is $0$, then we can define its potential energy to be \begin{align*}
  U_\text{pendulum} & = m_2 g y              \\
                    & = m_2 g l \cos \theta.
\end{align*}

Combining all of those energies gives a Lagrangian of \begin{align*}
  \mathcal{L} & = T - U                                                                                                                                     \\
              & = T_\text{cart} + T_\text{pendulum} - U_\text{cart} - U_\text{pendulum}                                                                     \\
              & = \frac{1}{2} m_1 \dot{x}^2 + \frac{1}{2} m_2 (\dot{x}^2 - 2 l \dot{\theta} \dot{x} \cos \theta + l^2 \dot{\theta}^2) - m_2 g l \cos \theta \\
              & = \frac{1}{2} (m_1 + m_2) \dot{x}^2 + \frac{1}{2} m_2 (l^2 \dot{\theta}^2 - 2 l \dot{\theta} \dot{x} \cos \theta) - m_2 g l \cos \theta.
\end{align*}

Now that we have the Lagrangian we can apply the Euler-Lagrange equation to each of the system's two coordinates $\theta$ and $x$. For $\theta$ we get \begin{align*}
  0 & = \frac{d}{d t} \frac{\partial \mathcal{L}}{\partial \dot{\theta}} - \frac{\partial \mathcal{L}}{\partial \theta}                 \\
    & = \frac{d}{d t} (m_2 l^2 \dot{\theta} - m_2 l \dot{x} \cos \theta) - m_2 l \dot{\theta} \dot{x} \sin \theta - m_2 g l \sin \theta \\
    & = l \ddot{\theta} - \ddot{x} \cos \theta - g \sin \theta
\end{align*} and for $x$ we get \begin{align*}
  0 & = \frac{d}{d t} \frac{\partial L}{\partial \dot{x}} - \frac{\partial \mathcal{L}}{\partial x} \\
    & = \frac{d}{d t} [(m_1 + m_2) \dot{x} - m_2 l \dot{\theta} \cos \theta]                        \\
    & = (m_1 + m_2) \ddot{x} - m_2 l \ddot{\theta} \cos \theta + m_2 l \dot{\theta}^2 \sin \theta.
\end{align*} Rearranging these two equations and solving for $\ddot{\theta}$ and $\ddot{x}$ gives us our equations of motion \begin{align*}
\ddot{\theta} & = \frac{(m_1 + m_2) g \sin \theta - m_2 l \dot{\theta}^2 \cos \theta \sin \theta}{l (m_1 + m_2) - m_2 l \cos^2 \theta} \\
\ddot{x}      & = \frac{m_2 \sin 2 \theta - 2 m_2 l \dot{\theta}^2 \sin \theta}{2 m_1 + m_2 - m_2 \cos 2 \theta}.
\end{align*}

Now that we've got them how do we know they're correct? One way would be to solve them for $\theta$ and $x$ and see if their predictions are reasonable. I certainly don't know how to solve them analytically, but we can solve them numerically. This is a Mathematica notebook I created to do just that. You can see we define some constants like gravity, the length of the pendulum, etc. We define the initial conditions for the simulation — here the pendulum is starting $\ang{30}$ from vertical. We solve the equations of motion numerically, and we generate an animation of the solution which you can see when I evaluate the notebook.

The pendulum swings back and forth as we expect, but interestingly it also causes the cart to move. This model doesn't include air resistance or friction so it'll keep swinging forever, but we can tweak the variables and see how that affects the solution. Let's try making the cart much heavier. It still moves, but much less than before, which makes sense.

\section{Linearisation}

These equations look good, but they're quite complicated so it might be difficult to analyse the stability of the system and determine how to control it. Can we simplify them at all? Well, one approach is to linearise them.

Linearising a function means finding a linear approximation of it at a particular point. For example, if we graph a function $y = f(x)$ and we want to linearise it at $x = 1$, we evaluate it at the point to find its $y$ coordinate, and we evaluate its derivative at the point to find its slope. Using this information we can plot a new function that passes through the point and extends the slope in both directions. It's a line. If you zoom in the line does a pretty good job of approximating the function. As you move away it doesn't do as good of a job, but if you only care about the area around the point that's fine.

\begin{figure}[H]
  \centering
\includegraphics[width=\textwidth]{linearisation}
\end{figure}

In the case of the pendulum, our goal is to keep the cart in the middle of the track, the pendulum upright, and neither the cart nor the pendulum moving. In other words, we want all four variables $\theta$, $\dot{\theta}$, $x$, and $\dot{x}$ to be $0$. The further they are from $0$ the less likely it is we'll be able to recover and we might have to accept that the pendulum's going to fall over or hit the end of the track. If they're always going to be near $0$ then it sounds like we can tolerate the approximation error and linearisation might work for us!

So how do we linearise our equations of motion? First, let's combine them into one vector-valued function \[\begin{bmatrix}
    \ddot{\theta} \\
    \ddot{x}
  \end{bmatrix} = \vec{f}(\theta, \dot{\theta}) = \begin{bmatrix}
    \frac{(m_1 + m_2) g \sin \theta - m_2 l \dot{\theta}^2 \cos \theta \sin \theta}{l (m_1 + m_2) - m_2 l \cos^2 \theta} \\
    \frac{m_2 \sin 2 \theta - 2 m_2 l \dot{\theta}^2 \sin \theta}{2 m_1 + m_2 - m_2 \cos 2 \theta}
\end{bmatrix}.\] Let's also introduce the state vector $\vec{x}$ which describes the state of the system \[\vec{x} = \begin{bmatrix}
    \theta       \\
    \dot{\theta} \\
    x            \\
    \dot{x}
\end{bmatrix}.\] Now we can change our function to just accept the state vector $\vec{x}$ \[\begin{bmatrix}
    \ddot{\theta} \\
    \ddot{x}
  \end{bmatrix} = \vec{f}(\vec{x}) = \begin{bmatrix}
    \frac{(m_1 + m_2) g \sin \theta - m_2 l \dot{\theta}^2 \cos \theta \sin \theta}{l (m_1 + m_2) - m_2 l \cos^2 \theta} \\
    \frac{m_2 \sin 2 \theta - 2 m_2 l \dot{\theta}^2 \sin \theta}{2 m_1 + m_2 - m_2 \cos 2 \theta}
\end{bmatrix}\] and if we include $\dot{\theta}$ and $\dot{x}$ in the output you can see that the function now returns the derivative of $\vec{x}$ \begin{align*}
  \begin{bmatrix}
    \dot{\theta}  \\
    \ddot{\theta} \\
    \dot{x}       \\
    \ddot{x}
  \end{bmatrix} & = \vec{f}(\vec{x}) = \begin{bmatrix}
                                         \dot{\theta}                                                                                                         \\
                                         \frac{(m_1 + m_2) g \sin \theta - m_2 l \dot{\theta}^2 \cos \theta \sin \theta}{l (m_1 + m_2) - m_2 l \cos^2 \theta} \\
                                         \dot{x}                                                                                                              \\
                                         \frac{m_2 \sin 2 \theta - 2 m_2 l \dot{\theta}^2 \sin \theta}{2 m_1 + m_2 - m_2 \cos 2 \theta}
                                       \end{bmatrix}    \\
  \dvec{x}         & = \vec{f}(\vec{x}) = \begin{bmatrix}
                                            \dot{\theta}                                                                                                         \\
                                            \frac{(m_1 + m_2) g \sin \theta - m_2 l \dot{\theta}^2 \cos \theta \sin \theta}{l (m_1 + m_2) - m_2 l \cos^2 \theta} \\
                                            \dot{x}                                                                                                              \\
                                            \frac{m_2 \sin 2 \theta - 2 m_2 l \dot{\theta}^2 \sin \theta}{2 m_1 + m_2 - m_2 \cos 2 \theta}
                                          \end{bmatrix}.
\end{align*}

The general equation to linearise a function like this is at a particular point $\vec{p}$ is \[\vec{f}(\vec{x}) \approx f(\vec{p}) + D \vec{f}|_{\vec{p}} (\vec{x} - \vec{p}).\] As I mentioned before we want to linearise our function at the point where all the elements of $\vec{x}$ are $0$. That means $\vec{p}$ is the zero vector \[\vec{f}(\vec{x}) \approx f \left( \begin{bmatrix}
      0 \\
      0 \\
      0 \\
      0
    \end{bmatrix} \right) + D \vec{f}|_{\vec{p}} \left( \vec{x} - \begin{bmatrix}
    0 \\
    0 \\
    0 \\
    0
\end{bmatrix} \right).\] Looking at the equations within $\vec{f}(\vec{x})$ you can see that at the point $\vec{p}$, $\dot{\theta}$ is $0$, the numerator of $\ddot{\theta}$ has a common term of $\sin \theta$ which is also $0$, $\dot{x}$ is $0$, and the numerator of $\ddot{x}$ contains the terms $\sin 2 \theta$ and $\sin \theta$, both of which are $0$. So $\vec{f}(\vec{p})$ is also the zero vector and we can remove it from our linearised function \[\vec{f}(\vec{x}) \approx D \vec{f}|_{\vec{p}} \vec{x}.\]

$D \vec{f}$ is called the Jacobian matrix of our function and $D \vec{f}|_{\vec{p}}$ is it evaluated at the point $\vec{p}$. It plays the same role the derivative did in the previous two-dimensional example — when you multiply it by a displacement vector $\vec{x}$ it tells you how much each component of the function differs from the point at which it was linearised. It's like extending the slope in each dimension. If we actually evaluate this at the point $\vec{p}$ we get \[D \vec{f}|_{\vec{p}} = \begin{bmatrix}
    0                           & 1 & 0 & 0 \\
    \frac{g (m_1 + m_2)}{l m_1} & 0 & 0 & 0 \\
    0                           & 0 & 0 & 1 \\
    \frac{g m_2}{m_1}           & 0 & 0 & 0
\end{bmatrix}.\] I'm going to call this matrix $\vec{A}$ which means the linearised version of our function is \[\dvec{x} = \vec{A} \vec{x} = \begin{bmatrix}
    0                           & 1 & 0 & 0 \\
    \frac{g (m_1 + m_2)}{l m_1} & 0 & 0 & 0 \\
    0                           & 0 & 0 & 1 \\
    \frac{g m_2}{m_1}           & 0 & 0 & 0
  \end{bmatrix} \vec{x}.\]

I've intentionally skimmed over some details in this section in the interests of time. If you'd like to learn more about linearising nonlinear systems and when it's actually valid to do that, these two videos from Steve Brunton are really great: \href{https://www.youtube.com/watch?v=RCWkzzLgwf0}{Linearizing Nonlinear Differential Equations Near a Fixed Point}, and \href{https://www.youtube.com/watch?v=vRaUSnB7qNw}{The Hartman-Grobman Theorem, Structural Stability of Linearization, and Stable/Unstable Manifolds}.

\section{Stability}

Now that we have a linearised version of our equations of motion we can apply some tools from linear control theory. One of those tools is stability analysis. This tells us that if any of the eigenvalues of our $\vec{A}$ matrix have a positive real component, the system is unstable. Our four eigenvalues are \[0, \ 0, \ -\sqrt{\frac{g (m_1 + m_2)}{l m_1}}, \text{ and } \sqrt{\frac{g (m_1 + m_2)}{l m_1}}.\] All of the values under that radical are positive, so the second two eigenvalues are real and the last eigenvalue is positive which tells us what we already know: the pendulum's going to fall over.

\section{Control}

I mentioned earlier that the cart moves left and right to keep the pendulum upright. A more formal way to say that is: we can say we apply a force $F$ on the cart in the $x$ direction. We can recalculate our equations of motion to include this force, the only difference is we apply d'Alembert's principle to the Euler-Lagrange equation for the $x$ coordinate and equate it to $F$. This results in the following updated equations of motion where I've hidden some terms so we can focus on the coefficients of $F$ \begin{align*}
  \ddot{\theta} & = f(\theta, \dot{\theta}) + \frac{\cos \theta}{l (m_1 + m_2) - l m_2 \cos^2 \theta} F \\
  \ddot{x}      & = g(\theta, \dot{\theta}) + \frac{2}{2 m_1 + m_2 - m_2 \cos 2 \theta} F.
\end{align*} Again, our goal is for $\theta$ to be close to $0$ so we can use the small angle approximation where $\cos \theta = 1$ and that gives the simplified equations \begin{align*}
  \ddot{\theta} & = f(\theta, \dot{\theta}) + \frac{1}{l m_1} F \\
  \ddot{x}      & = g(\theta, \dot{\theta}) + \frac{1}{m_1} F.
\end{align*} If we use the coefficients of $F$ to create a new matrix $\vec{B}$ and substitute this into our linearised equations of motion we get \begin{align*}
  \dvec{x} & = \vec{A} \vec{x} + \vec{B} F              \\
           & = \begin{bmatrix}
                 0                           & 1 & 0 & 0 \\
                 \frac{g (m_1 + m_2)}{l m_1} & 0 & 0 & 0 \\
                 0                           & 0 & 0 & 1 \\
                 \frac{g m_2}{m_1}           & 0 & 0 & 0
               \end{bmatrix} \vec{x} + \begin{bmatrix}
                                         0               \\
                                         \frac{1}{l m_1} \\
                                         0               \\
                                         \frac{1}{m_1}
                                       \end{bmatrix} F.
\end{align*}

Another useful tool from control theory is the concept of controllability. A system is said to be controllable if it's possible to move it into any state you want using only its inputs. In our case, the only input is $F$ — is that enough to control the system? It is if the rank of the controllability matrix equals the dimension of the state space \[\rank(\vec{C}) = \rank(\begin{bmatrix}
      \vec{B} & \vec{A} \vec{B} & \vec{A}^2 \vec{B} & \cdots & \vec{A}^{n - 1} \vec{B}
    \end{bmatrix}) = n.\] If we perform this calculation using our $\vec{A}$ and $\vec{B}$ matrices we get the value $4$. This is the dimension of our state vector and so we can control the system using the force $F$.

Now we have a way to control the system, but how do we choose $F$? Obviously we want it to be a function of the state of the system — for example, if the pendulum is close to vertical we want to apply a small force but if it's far from vertical we want to apply a larger force. This suggests we could define it as \[F = \vec{K} \vec{x}\] where $\vec{K}$ is a row matrix. Conventionally this is written as \[F = -\vec{K} \vec{x}.\]

If we substitute this into our linearised equation of motion we get \begin{align*}
  \dvec{x} & = \vec{A} \vec{x} - \vec{B} \vec{K} \vec{x} \\
           & = (\vec{A} - \vec{B} \vec{K}) \vec{x}.
\end{align*} This looks very similar to the original equation but $\vec{A}$ has been replaced by $\vec{A} - \vec{B} \vec{K}$. If we can choose $\vec{K}$ in such a way that the eigenvalues of this new matrix don't have positive real components, the system will be stable.

So how do we choose $\vec{K}$? One approach is to use the Linear Quadratic Regulator algorithm. Now I don't completely understand how this works, but thankfully there's a Mathematica function that does. It accepts our matrices $\vec{A}$ and $\vec{B}$ plus two additional matrices that define how much it ``costs'' to apply a force to the cart and for each variable to differ from $0$. For example, if we don't want to use much electricity running the motor we could set the force cost high and the resulting $\vec{K}$ matrix would minimise its use. Or if we don't want the cart to move far from the centre of the track we could set the $x$ cost high and the matrix would try to minimise it but possibly at the expense of another variable like the pendulum angle.

This Mathematica notebook calculates the $\vec{K}$ matrix and generates an animation of a pendulum controlled by it. Like the last notebook, we define some constants, initial conditions, our $\vec{A}$ and $\vec{B}$ matrices, our cost matrices, we calculate $\vec{K}$, confirm its eigenvalues don't have positive real parts, and finally generate an animation. If I evaluate the notebook we get our $\vec{K}$ matrix, we can see its eigenvalues don't have positive real parts so the system is stable, and we can play our animation. It looks good! Let's see what happens if we tweak the cost matrix. I'll increase the cost of applying a force to the cart. Regenerating the animation, we can see the cart moves much further from the centre of the track because it's trying to minimise the applied force.

\end{document}